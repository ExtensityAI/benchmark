\section{Framework}

Within this section, we deliberate on the decisions foundational to the implementation and the intricacies inherent to the framework we have adopted.

Comparable to the pervasive \texttt{object} in Python, the cornerstone of SymbolicAI is the \texttt{Symbol}, epitomized by its namesake basic type. A \texttt{Symbol} object signifies an indivisible atomic entity. All succeeding sub-types, like \texttt{Expression} and its kin, echo their mathematical counterparts by embodying expressions or entities poised for further elucidation and refinement.
Inheriting from \texttt{Symbol} are fundamental attributes, elemental operators, and auxiliary methods permeating these sub-types. In addition, each \texttt{Symbol} encompasses both scalar and vectorial representations, accessible via \texttt{value} and \texttt{embedding} attributes, respectively. The latter is crucially deployed for infusing a symbolâ€™s prevailing milieu, paralleling the embedding of text and its subsequent encapsulation as a PyTorch tensor. While to an LLM the numerical tensors might stand void of intrinsic meaning, the vectorial portrayals are pivotal: as singular symbols amalgamate into elaborated constructs, these embedded tensors are poised for contextual rejuvenation through gradient based optimization. Such versatility underpins a decisive role within the fluid realm of symbolic discourse, particularly when forging self-augmenting systems.

Forging a bridge between symbols and LLMs presupposes that each \texttt{Symbol} interweaves seamlessly with Python's intrinsic string utilities, a feat accomplished by the \texttt{\_\_str\_\_} method which confers a string portrayal. It is noteworthy that transmuting a multifaceted object to a string may at times impede flawless reconstitution of said object. Nevertheless, this impediment scarcely detracts from our approach: through the leverage of vectors furnished by the embedding feature, we adeptly navigate proxies or approximative representations to effectively retrace objects. These portrayals are sourced from dedicated embedding models. Consequently, we assert with theoretical conviction that any Python object, by virtue of design, \emph{is} interpretable by an LLM.