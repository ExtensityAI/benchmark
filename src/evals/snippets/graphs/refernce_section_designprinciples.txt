\section{Design Principles}\label{sec:sym&expr}
In the following sub-sections, we elaborate on the key design principles underlying SymbolicAI and how we guide the generative processes.

\paragraph{Symbols and Expressions} As posited by Newell and Simon \citep{NewellSimon:76}, symbols are elemental carriers of meaning within a computational context.
These symbols define physical patterns capable of composing complex structures, and are central to the design and interpretation of logic and knowledge representations \citep{Augusto:22}.
Thus, SymbolicAI conceptualizes the notion that symbols, and the expressions they form, are reflections of the information inherent in a system, and serve as surrogate for the interaction between the system and the problem space.
Moreover, we argue that \emph{real patterns}, as Dennett \citep{Dennett:91} speaks of, can be effectively realized through the use of symbols because these symbols act as versatile abstractions that capture and represent the underlying structures and dynamics of these patterns, facilitating their interpretation and manipulation in computational models.
To the best of our knowledge, this is the first work to establish a direct link between Dennett's concept of real patterns and the symbolic representations proposed by Newell and Simon.

Furthermore, we attribute task-specific mappings to a language-centric strategy, leveraging their inherent semantics and abstraction to describe the states and properties of the problem at hand.
These mappings are universal and may be used to define scene descriptions, long-horizon planning, acoustic properties, emotional states, physical conditions, etc.
Therefore, we adhere to the analogy of language representing the \emph{convex hull of the knowledge of our society}, utilizing it as a fundamental tool to interpret symbols.
This approach allows us to map the complexities of the world onto language, where language itself serves as a comprehensive, yet abstract, framework encapsulating the diversity of these symbols and their meanings.
This perspective resonates with our innate human tendencies to attribute existing physical objects with abstract concepts, as exemplified by our natural inclination to link tangible objects to colors and emotions, such as correlating the color "\emph{red}" with "\emph{heart}", "\emph{warm}", and "\emph{passion}".

However, this language-centric model does not inherently encompass all forms of representation, such as sensory inputs and non-discrete elements, necessitating the establishment of additional mappings to fully capture the breadth of the world.
This requirement is manageable, as it allows us to engage in operations within this abstract conceptual space, facilitating the discovery of corresponding mappings back to the original problem space.
These are typically applied through function approximation, as in typical \emph{modality}-to-language and language-to-\emph{modality} use cases, where modality is a placeholder for various skill sets such as text, image, video, audio, motion, etc.

Ultimately, this approach also anchors our work in the field of formal language theory, as it necessitates a structured method to construct mappings from the world to language.
This grounding sets the foundation for employing formal language structures, such as grammars, to systematically define our language-centric approach to problem-solving and the associated translation of real-world complexities into linguistic terms.

\paragraph{Formal Languages}
In formal language theory and linguistics, languages are structured following the Chomsky hierarchy, which classifies languages by the complexity of their grammatical structure \citep{Chomsky:56}. This hierarchy, comprising four types of grammars (Type-3 to Type-0), delineates formal languages by their grammatical complexity. A grammar in this context consists of terminal and non-terminal symbols, production rules, and a designated \emph{start symbol}, facilitating the generation of valid strings within a language. In implementing the SymbolicAI framework, we posit that all symbols can be represented as strings, augmented with conditional instructions and types derived from a domain-specific language (DSL) tailored for directing NeSy computation engines, like LLMs. However, this framework is not restricted to LLMs; any symbolic or sub-symbolic engine capable of leveraging unrestricted grammars can interpret these instructions.

A key advancement of LLMs over previous systems lies in their ability to generalize from formal languages \citep{Wang:23} and knowledge systems, primarily due to their world-knowledge and proficiency in understanding context-based analogies.
While there is currently no universal consensus among experts regarding the precise classification of natural language within the Chomsky hierarchy, we have utilized LLMs as \emph{semantic interpreters}.
This approach can be viewed as employing a form of \emph{flexible}, context-sensitive grammar, which enables the processing of instructions and analogies with a nuanced understanding of language's inherent variability and complexity.
The intersection between formal and natural languages becomes evident when considering how language patterns, such as prompts like "\emph{You are a helpful assistant...}", elicit structured responses, indicating a potential underlying formal mechanism at play.
This observation underlines the utility of such a grammar in our framework, particularly within in-context learning, where it serves as an explicit schema guiding the structure of examples used in few-shot learning scenarios.
For instance, equating "\emph{3.1415…}" with "\emph{π}" or "\emph{August 4, 1961}" with "\emph{1961-08-04}" in a given context demonstrates this probabilistic, context-dependent interpretation of symbols.
Such a system doesn't rigidly adhere to standard grammatical rules but instead adjusts and interprets based on the presented context, effectively creating a dynamic and situation-specific grammar.

\paragraph{In-Context Learning}
Recently, several in-context learning methodologies evolved to enable tool usage \citep{Schick:23}, or refine the generative outcome of LLMs \citep{Yang:23}.
This includes chain-of-thought (CoT) prompting, a method that conditions the model to reveal its step-by-step reasoning process \citep{Singhal:23, Wei:23}.
CoT prompting breaks down complex tasks into simpler, sequential steps, and helps with interpreting LLM's output.
Self-generated CoT, where models are encouraged to generate their own reasoning chains based on training examples, surpasses even expertly crafted CoT \citep{Fernando:23}.
This observation echoes other reports that GPT-4 has an emergent self-improving capability via introspection, such as self-verification \citep{Weng:23} or self-consistency \citep{Wang:23consistency}.
Tree of Thoughts (ToT) enables LLMs to solve complex problems by exploring multiple reasoning paths through a search tree of coherent text units, demonstrating significant problem-solving enhancements in tasks requiring strategic planning and search \citep{Yao:23}.
Ensemble techniques further enhance the robustness and accuracy of model predictions by combining several strategies to establish a consensus \citep{Nori:23}.
Conceptually, we designed our framework to enable all these techniques and combine them into dedicated components and sub-processes.

\paragraph{Domain-Invariant Associations}
In-context learning enabled LLMs to become versatile task solvers by interpolating within the training distribution, to the extent that even potentially unseen tasks are addressable \citep{Brown:20}.
We attribute this to associations formed within the input space and the capacity of Transformer architectures for defining domain-invariant feature sub-spaces.
This phenomenon has striking parallels with advancements in few-shot learning approaches such as SubGD \citep{Gauch:22}, a method based on identifying and utilizing a low-dimensional subspace, learned from various tasks, that effectively acts to regularize the learning process, representing features that are invariant across different learning tasks.
Furthermore, SubGD reflects the potential of in-context learning when combined with task-specific fine-tuning by showing that fine-tuning within a learned subspace significantly outperforms traditional fine-tuning methods.
We believe that the extent of in-context learning is not yet exhausted, holding considerable promise when integrated with task-specific fine-tuning and solvers.
To develop learning and reasoning systems capable of general problem-solving, we adopt a hybrid methodology.
This approach leverages the in-context generalization capability of LLMs, constructing symbolic associations that aim to preserve and propagate the context, and validating them against verifiable solutions.

\paragraph{Function Composition}
In SymbolicAI, function composition is pivotal for constructing complex hierarchies and behaviors from more basic, fundamental elements.
It enables our framework to model interconnected processes, where the output of one function seamlessly transitions into the input of another, thus creating a cohesive sequence of operations.
Through function composition, we construct computational graphs, in which intermediate symbols represent the nodes or states within these graphs.
Formally, function composition is denoted by \( \circ \), where combining functions \( f \) and \( g \) yields a new function \( h = g \circ f \), defined as \( h(x) = g(f(x)) \)
For functions \( f : X \rightarrow Y \) and \( g : Y \rightarrow Z \), their composition results in a function mapping elements from domain \( X \) to codomain \( Z \) through \( g(f(x)) \).

Although traditionally the codomain of the inner function \( f \) aligns with the domain of the outer function \( g \), SymbolicAI relaxes this constraint by allowing for any subset relationship between these domains and codomains, enhancing data flow flexibility.
For example, this relaxed constraint in domain and codomain alignment is particularly beneficial for in-context learning.
By leveraging functional few-shot learning, where few-shot examples act as dynamic elements of the function's domain, SymbolicAI enhances its ability to interpret and respond to diverse input contexts.
Therefore in SymbolicAI, the use of composition leads to the creation of richer and more nuanced symbol-based generative flows, where each functional unit is capable of representing either logical or data-driven behaviors.
Importantly, function composition is not confined to strictly symbolic representations; it also encompasses and connects with sub-symbolic processes.
This enables SymbolicAI to handle complex data streams, establishing it as a central tenet in bridging multiple modalities and coordinating a variety of tasks.
